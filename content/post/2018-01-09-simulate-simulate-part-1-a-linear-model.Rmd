---
title: 'Simulate! Simulate! - Part 1: A linear model'
author: Ariel Muldoon
date: '2018-01-09'
slug: simulate-simulate-part1
categories: [r, statistics]
tags: [simulation, teaching]
draft: TRUE
description: "Where I discuss simulations, why I love them, and get started on a simulation series with a simple two-group linear model."
---

I have to confess:  I love simulations.  

I use simulations to check my intuition and understanding of statistical theory.  When someone tells me with great certainty "I don't need to meet that assumption for this because [fill in the blank]", I tend turn to simulations rather than textbooks to check.

I like simulations for the same reasons I like building Bayesian models and using resampling methods (i.e., Monte Carlo) for inference.  Building the simulation increases my understanding of the problem and makes all the assumptions I am making clearer to me.

# Simulate, simulate, dance to the music

I would like to use simulations more in teaching and consulting to help folks understand their models better.  I co-instruct a data analysis/mixed models course winter term, but we've had a difficult time fitting simulations in; there's just too many other things that we have to cover in only eight weeks of instruction.

It was when switiching to using mixed models in R from SAS when I really started using simulations heavily.  But I thought it worthwhile to start out with a simpler model.  Today I'll go over a simulation from a two-group linear model and then work up to linear mixed models and generalized linear mixed models in subsequent posts.

# The statistical model

**Warning: Here be some equations.**  

This is where my brain likes to say, "I think this section doesn't pertain to me."  If this is you, you can jump right down to the R code in the next section.

A simulation for a linear model is based on the statistical model. The statistical model is an equation that describes the processes we believe gave rise to the observed response variable.  It includes parameters to describe the assumed effect of explanatory variables on the response variable as well as a description of any distributions associated with processes we assume are random variation. (See Stroup's 2015 "Generalized Linear Mixed Models" book for a more in-depth description).

Here is an example of a linear model for two groups.  I wrote the statistical model to match the form of the default output of `lm` in R.

$$y_t \thicksim \beta_0 + \beta_1(group_t=\textit{''group''}) + \epsilon_t$$

+ $y_t$ is the observed, quantitative response variable for every observation, $t$ = 1-number of observations in the dataset  
+ $\beta_0$ is the mean response variable when the group is "group1"
+ $\beta_1$ is the difference in mean response of "group2" from "group1"
+ $\epsilon_t$ is the random variation present for each observation that is not explained by the group variable.  These are assumed to come from an iid normal distribution with some shared variance, $\epsilon_t \thicksim N(0, \sigma^2)$

# Do one simulation from a two-group model

Now I can use the statistical model to build a simulation.  In this case I'll call my response variable "growth", and the two groups "group1" and "group2".  I'll have 10 observations per group (it's possibly to simulate unbalanced groups but balanced groups is a good place to start).

I'll set my seed so I can replicate this you can replicate this simulation exactly at home.

```{r}
set.seed(16)
```


I like to start out by defining what the "truth" is in the simulation by setting parameter values.  Here's what I'll do today.

+ The true group mean for "group1" will be 5 ($\beta_0$)
+ The mean of "group2" will be 2 less than "group1" ($\beta_1$)
+ The shared variance will be set at 4 ($\sigma^2$) so the standard deviation ($\sigma$) is 2.

I'll define the number of groups and number of replicates per group while I'm at it.  The total number of obserations is the number of groups times the number of replicates per group.

```{r}
ngroup = 2
nrep = 10
b0 = 5
b1 = -2
sd = 2
```

I also need to create the variable "group".  I use `rep` a lot when doing simulations in order to repeat values of variables the correct amount of times.  Here I'll repeat each level of "group" 10 times.

```{r}
( group = rep( c("group1", "group2"), each = nrep) )
```

I create a variable for the random errors by drawing from a normal distribution with a mean of 0 and standard deviation of 2.  I need one error for every observation, so will make 20 draws total from this distribution.

```{r}
( eps = rnorm(ngroup*nrep, 0, sd) )
```

I have all the pieces, so I can add everything together based on the statistical model.  I use an indicator variable so ($\beta_1$) is only added when `group == "group2"`.

```{r}
( growth = b0 + b1*(group == "group2") + eps )
```

I've been working with vectors, but I like to put my "variables" in a dataset.

```{r}
growthdat = data.frame(growth, group)
```

Which can be used to fit a model.  This is a simulation that has random noise, 

```{r}
growthfit = lm(growth ~ group, data = growthdat)
summary(growthfit)
```

