---
title: How to plot fitted lines with ggplot2
author: Ariel Muldoon
date: '2018-11-14'
slug: plot-fitted-lines
categories:
  - r
tags:
  - ggplot2
draft: TRUE
description: "Plotting the fitted relationship can be the culmination of an analysis.  Here I show a general approach that will works across many different model types for making plots with ggplot2."
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(comment = "#")
```

Most analyses aren't really done until we've found a way to visualize the results graphically.  There are some R packages that are made specifically for this purpose. See packages **effects** and **visreg**, for example.

If using the **ggplot2** package for plotting, simple models can be graphed using `geom_smooth()`.  However, once models get more complicated that convenient function is no longer useful.  I'll go over the basic approach that I use for plotting fitted lines in **ggplot2** that can be used across many model types.

# Load packages and dataset

First I'll load the packages I'm using today.

```{r, message = FALSE}
library(nlme) # v. 3.1-137
library(ggplot2) # v. 3.1.0
```

I created a dataset to use for fitting models elsewhere and used `dput()` to copy and paste it here.

```{r, eval = FALSE, echo = FALSE}
# Code for making dataset 
     # (although I didn't set seed so making again will be different)
dat = data.frame(block = rep(LETTERS[1:10], each = 4),
                 group = rep(letters[1:4], times = 10),
                 x1 = runif(40, 4, 16),
                 x2 = runif(40, 100, 200))

dat$resp = with(dat, 2*(group == "a") + 20*(group == "b") +
                     -10*(group == "c") + 4*(group == "d") +
                     10*x1 + -.25*x2 +
                     rep(rnorm(10, 0, 1), each = 4) +
                     rnorm(40, 0, 2))

dat = mutate_if(dat, is.numeric, round, digits = 1)

dput(dat)
```

```{r}
dat = structure(list(block = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 
6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 
10L, 10L), .Label = c("A", "B", "C", "D", "E", "F", "G", "H", 
"I", "J"), class = "factor"), group = structure(c(1L, 2L, 3L, 
4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 
4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 
4L, 1L, 2L, 3L, 4L), .Label = c("a", "b", "c", "d"), class = "factor"), 
    x1 = c(11.1, 7.9, 6.6, 7.1, 10.6, 8, 9.8, 8.2, 9.5, 5.4, 
    15, 15.3, 10.4, 5.5, 9.1, 15.3, 12.9, 9.9, 5, 7.4, 10.4, 
    8.2, 14.1, 4.7, 11.9, 12.5, 8.7, 7, 5.5, 5.7, 13.7, 11.8, 
    7, 14.8, 4.9, 14.3, 7.8, 15.4, 15.2, 12.2), x2 = c(109.9, 
    149.2, 187.4, 124.1, 190.7, 145, 110.1, 114.1, 119.9, 163.8, 
    192.7, 158.3, 180.5, 127.7, 133.1, 137.5, 167.8, 181.8, 156.4, 
    109.7, 143.9, 194.2, 139.1, 112.4, 194, 125.7, 127, 149.1, 
    117.8, 170.4, 167.3, 101.1, 128, 157.8, 139.7, 193.6, 121.1, 
    161.1, 112, 137.3), resp = c(86.5, 63.1, 10.5, 44.4, 61.9, 
    67.7, 64.1, 59.4, 66.1, 33.2, 91.6, 116.4, 59.4, 38.6, 44.6, 
    122.9, 87.1, 75.1, -0.8, 49.1, 70.2, 57.8, 96.4, 22.5, 74.7, 
    116.7, 46, 39.8, 28.3, 34.1, 87, 97.1, 37.3, 126.8, 2.2, 
    96.1, 45.3, 131.9, 107.6, 92.7)), class = "data.frame", row.names = c(NA, 
-40L))
```

This dataset has one "response" variable, `resp`, along with two continuous (`x1`, `x2`) and one categorical (`group`) explanatory variables. The data were collected from a blocked design, and the `block` variable is to be used as a random effect.

```{r}
head(dat)
```

# [Plotting separate slopes with geom_smooth()](#plotting-separate-slopes-with-geom_smooth)

The `geom_smooth()` function in **ggplot2** can show fitted lines from a variety of simple models, including models fit with `lm()`, `glm()`, `nls()`, and `mgcv::gam()`.  

Fitted lines can vary by groups if a factor is mapped to an aesthetic like `color` or `group`.  I'm going to plot fitted regression lines of `resp` vs `x1` for each `group`.

By default you will get confidence intervals plotted in `geom_smooth()`. This is great if you are plotting the results after you've checked all assumptions but is not-so-great if you are exploring the data.  Confidence intervals can be supressed using `se = FALSE`, which I use below.

```{r}
ggplot(dat, aes(x = x1, y = resp, color = group) ) +
     geom_point() +
     geom_smooth(method = "lm", se = FALSE)
```

Here is the plot with confidence envelopes as ribbons around the fitted lines, making the ribbons the same color as the lines.  I increased the transparency of the ribbons by decreasing `alpha` since adding confidence ribbons for many fitted lines in one plot can end up looking pretty messy.

```{r}
ggplot(dat, aes(x = x1, y = resp, color = group) ) +
     geom_point() +
     geom_smooth(method = "lm", alpha = .1, aes(fill = group))
```

# [Getting predicted values from the model](#getting-predicted-values-from-the-model)

In the plots above you can see that the slopes vary by group.  If you want parallel lines instead of separate slopes per group, `geom_smooth()` isn't going to work for you.

Instead we can get predicted values from the model outside of our plot and use those for drawing the fitted line.  For many model types this can be done with the `predict()` function.  

You can check if the model you are using has a predict function via `methods()`. For example, `methods("predict")` lists all the different model objects that have specific `predict()` functions.  Since I've loaded packages **nlme** you can see `predict.lme` and `predict.gls` along with many others.

```{r}
methods("predict")
```

To see the help page for the `predict()` function for a specific model type, you can use the function and class information together to get to the correct documentation.  So, e.g., `?predict.lme` will take you to the documentation for the predict function for `lme` objects fit with `nlme::lme()`.

# [Plotting parallel fitted lines](#plotting-parallel-fitted-lines)

The first thing to do is fit the model.  I'll use a linear model with different intercepts for each `group` and single `x1` slope to end up with parallel lines per group.

```{r}
fitlm = lm(resp ~ group + x1, data = dat)
```

I can add the predicted values to the dataset.

```{r}
dat$predlm = predict(fitlm)
```

And then use these in `geom_line()` to add fitted lines based on the new `predlm` variable.

```{r}
ggplot(dat, aes(x = x1, y = resp, color = group) ) +
     geom_point() +
     geom_line(aes(y = predlm), size = 1)
```

# [Confidence intervals for lm objects](#confidence-intervals-for-lm-objects)

What about confidence intervals?  The `predict()` function for `lm` objects has an `interval` argument that returns confidence or prediction intervals, which is appropriate if model assumptions have been reasonably met.  I'm skipping the assumption-checking step here. `r emo::ji("wink")`

Adding `interval = "confidence"` returns a three column matrix, where `fit` is the fitted values, `lwr` is the lower 95% confidence interval limit and `upr` is the upper 95% confidence interval limit.

```{r}
predslm = predict(fitlm, interval = "confidence")
head(predslm)
```

These columns can be bound to `dat` for plotting.

```{r}
datlm = cbind(dat, predslm)
head(datlm)
```

Now we can plot the lines using `geom_line()` and a confidence envelope via `geom_ribbon()`.  Note I have to use `alpha` to make the ribbon transparent.  I put the ribbon layer before the line so the line is drawn on top of the ribbon.

The `color` aesthetic affects the ribbon outline.  To remove that I map the group variable to the `fill` aesthetic and use `color = NULL` to remove the outlines.

```{r}
ggplot(datlm, aes(x = x1, y = resp, color = group) ) +
     geom_point() +
     geom_ribbon( aes(ymin = lwr, ymax = upr, fill = group, color = NULL), alpha = .1) +
     geom_line( aes(y = fit), size = 1)
```

# [Using a new dataset with predict()](#using-a-new-dataset-with-predict)

The lines in the last two plots are different lengths.  This is because we have slightly different ranges of `x1` for each group in our dataset.  By default when using `predict()` we get *fitted values*; i.e., the predicted values from the dataset used for model fitting.

I think having different line lengths is fine here, but there are times when we want to draw each line across the entire range of the variable in the dataset.  Also, sometimes our data are so sparse that our fitted line isn't very smooth; this can be especially problematic for non-linear fits.  In both of these situations we'd want to make a new dataset for making predictions.

In this case we want predicted values for entire range of `x1` in the dataset for each group.  Getting the full range of `x1` can be done via `seq()`, making a sequence from the minimum to maximum values.  I use 0.1 as the increment in `seq()`, but this value depends on the range of your variable.  

To get this full range `x1` for each group we can use `expand.grid()`.

The real key to making a dataset for prediction is that it *must have every variable used in the model in it*.  Note it does not need to contains the response variable.

```{r}
newdat = expand.grid(x1 = seq(min(dat$x1), max(dat$x1), by = .1),
                     group = unique(dat$group))
```

We can use this with the `newdata` argument in predict.  I'll add the fitted values to the prediction dataset.

```{r}
newdat$predlm = predict(fitlm, newdata = newdat)
```

And now the line for each group covers the same range.  You see I used the `newdat` dataset within `geom_line()` but plotted the original data from `dat` for the points.

```{r}
ggplot(dat, aes(x = x1, y = resp, color = group) ) +
     geom_point() +
     geom_line(data = newdat, aes(y = predlm), size = 1)
```

# [Plotting fitted lines from lme object](#plotting-fitted-lines-from-lme-object)

The approach I'm demonstrating where I calcualte predicted values for plotting fitted lines works across many model types.  

To show another example, I'll fit the model that the "real" model.  This is the model that I used to create `resp`.  This model has all three explanatory variables as fixed effects with no interactions along with the random effect of `block`.

```{r}
fitlme = lme(resp ~ group + x1 + x2, 
             random = ~1|block,
             data = dat)
```

We can make predictions via the predict function for `lme` objects.  However, since I have two continouous explanatory variables I'll have to do this for one variable while holding the other fixed.  This is called an *added variable plot*, [which I've written about before](https://aosmith.rbind.io/2018/01/31/added-variable-plots/).

I'll focus on making a plot for `x1` while holding `x2` at its median.  I'll make a new dataset for prediction since `x2` will be a constant instead of the original data.  

```{r}
newdat.lme = data.frame(group = dat$group,
                        x1 = dat$x1,
                        x2 = median(dat$x2))
head(newdat.lme)
```

I'm only interested in the fitted lines from the fixed effects, so I didn't include `block` in my new dataset.  I use `level = 0` to get on the *marginal* or *population* predictions (this is equivalent to `re.form = NA` for **lme4** models).  See `?predict.lme` for more info.  If I wanted conditional predictions `block` would need to be part of `newdat.lme`.

```{r}
newdat.lme$predlme = predict(fitlme, newdata = newdat.lme, level = 0)
```

Now I have the values for the plot.  Since this is an added variable plot it can be confusing to plot the line directly on top of the raw data, so I switch to a rug plot for the `x` axis (I'm not sure about having the colors in the rug, but I left them).

```{r}
ggplot(dat, aes(x = x1, y = resp, color = group) ) +
     geom_rug(sides = "b", size = 1) +
     geom_line(data = newdat.lme, aes(y = predlme), size = 1)
```

# [Adding confidence intervals for lme objects](#adding-confidence-intervals-for-lme-objects)

What if we wanted to add confidence interval ribbons?  You'll see `predict.lme` does not have an option to get confidence intervals or calculate standard errors that could be used to build confidence intervals.  I use the recipe from the [GLMM FAQ maintained by Ben Bolker](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions), although this approach does not take the uncertainty of the random effects into account.

This approach involves getting the model matrix $X$, the covariance matrix of the parameters $V$, and calculating $XVX'$.

First we get the model matrix using the new dataset.  It looks extra complicated because we don't have `resp` in the prediction dataset.

```{r}
des = model.matrix(formula(fitlme)[-2], newdat.lme)
```

Then we use matrix multiplication on the model matrix and variance-covariance matrix extracted with `vcov()`.  We pull out the values on the diagonal, which are the variances of the predicted values.

```{r}
predvar = diag(des %*% vcov(fitlme) %*% t(des))
```

To construct approximate confidence intervals we use the standard errors (square root of `predvar`) along with a multiplier.  I'm using 2 as a multiplier, but you could also figure out the appropriate $t$ multiplier based on the degrees of freedom or use 1.96 as a $z$ multiplier.

I add the confidence interval limits to the dataset for plotting.

```{r}
newdat.lme$lower = with(newdat.lme, predlme - 2*sqrt(predvar) )
newdat.lme$upper = with(newdat.lme, predlme + 2*sqrt(predvar) )
```

And the plot, with the added (but very small) confidence ribbon.

```{r}
ggplot(dat, aes(x = x1, y = resp, color = group) ) +
     geom_rug(sides = "b", size = 1) +
     geom_ribbon(data = newdat.lme, aes(y = NULL, ymin = lower, ymax = upper, 
                                        color = NULL, fill = group),
                 alpha = .1) +
          geom_line(data = newdat.lme, aes(y = predlme), size = .75)
```

# [What if there is no predict() function?](#what-if-there-is-no-predict-function)

The vast majority of modeling packages these days have `predict()` functions.  If the one you are using doesn't, though, you can usually do your own predictions with matrix multiplication of the model matrix and the fixed effects.  You can see an example for the **glmmADMB** package from the GLMM FAQ  [here](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#glmmadmb).
