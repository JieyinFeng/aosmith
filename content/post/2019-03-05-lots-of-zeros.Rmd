---
title: 'Lots of zeros or too many zeros?: thinking about zero-inflation'
author: Ariel Muldoon
date: '2019-03-05'
slug: lots-of-zeros
categories:
  - statistics
  - r
tags:
  - glmm
  - simulation
  - teaching
draft: TRUE
description: "When working with counts, having 0 values does not necessarily indicate zero-inflation.  I demonstrate this by simulating data data simulated the negative binomial and generalized Poisson distributions.  I finish by talking about how to check if the model you fit models the number of 0 values in the data well."
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(comment = "#")
```

As part of a class I was teaching, I gave an brief introduction to generalized linear models (GLM) this quarter.  You can't get into much detail in on GLM's just four class periods weeks, but I did manage to work in a bit of info on zero inflation with count distributions.  One take-home message that I thought worth repeating here is that having a lot of zero values does not necessarily mean you have zero inflation.

Zero inflation is when there are more 0 values in the data than the distribution allows for.  But some distributions can have a lot of zeros!

# Load packages and dataset

I'm going to be simulating counts from distributions to demonstrate this.  Before I get to that, I'll load the packages I'm using today.

Package **HMMpa** is for drawing random samples from the generalized Poisson distribution and **VGAM** for drawing from a zero-inflated negative binomial distribution.

```{r, message = FALSE}
library(ggplot2) # v. 3.1.0
library(HMMpa) # v. 1.0.1
library(MASS) # v. 7.3-51.1
library(VGAM) # v. 1.1-1
```

# [Negative binomial with many zeros](negative-binomial-with-many-zeros)

First I'll draw 200 counts from a negative binomial with $\lambda = 10$ and $\theta = 0.05$.  R generally uses the parameterization where the variance of the distribution is $\lambda + (\lambda^2/\theta)$, so as $\theta$ gets small the variance gets big.

I make random draws from this simple distribution using `rnbinom()`.  The `mu` argument is the mean and the `size` argument is theta.  Using such a small $\theta$ in the simulation will generally return lots of 0 values as well as a few very large values.

```{r}
set.seed(16)
dat = data.frame(Y = rnbinom(200, mu = 10, size = .05) )
```

Here is a histogram of these data.  I've added info to the plot on the proportion of the 200 values that are 0 as well as the maximum observed count in the dataset.  There are lots of zeros!

```{r}
ggplot(dat, aes(x = Y) ) +
	geom_histogram(binwidth = 5)  +
	theme_bw(base_size = 18) +
	labs(y = "Frequency",
	     title = "Negative binomial",
	     subtitle = "lambda = 10, theta = 0.05" ) +
	annotate(geom = "text",
		    label = paste("Proportion 0:", mean(dat$Y == 0), 
		    		    "\nMax Count:", max(dat$Y) ),
		    		    x = 150, y = 100, size = 8)

```

# [Generalized Poisson with many zeros](#generalized-poisson-with-many-zeros)

I don't know the generalized Poisson distribution well, although it seems to be common in some fields.  For whatever reason, the negative binomial seems much more common in ecology.  From my understanding, this distribution can have heavier tails than the negative binomial, so it can have more extreme maximum counts as well as lots of zeros.

See the documentation for `rgenpois()` for the formula for the density and definitions of mean and variance.  Note that when `lambda2` is 0, the generalized Poisson reduces to the Poisson.


```{r}
set.seed(16)
dat = data.frame(Y = rgenpois(200, lambda1 = 0.5, lambda2 = 0.95) )
```

Here is a histogram of these data.  There are only a little over 50% zeros but the maximum count is over 1000! `r emo::ji("open_mouth")`

```{r}
ggplot(dat, aes(x = Y) ) +
	geom_histogram(binwidth = 5)  +
	theme_bw(base_size = 18) +
	labs(y = "Frequency",
	     title = "Generalized Poisson",
	     subtitle = "lambda1 = 0.5, lambda2 = 0.95") +
	annotate(geom = "text",
		    label = paste("Proportion 0:", mean(dat$Y == 0), 
		    		    "\nMax Count:", max(dat$Y) ),
		    		    x = 600, y = 100, size = 8)

```

# [Lots of zeros or excess zeros?](#lots-of-zeros-or-excess-zeros)

All the simulations above show us is that some distributions *can* have a lot of zeros.  In any given scenario, though, how do we check if we have *excess* zeros (i.e., more than the distribution we are using for modeling allows)?  If we have excess zeros than we may either need a different distribution or we could think about models that specifically address zero-inflation.

The key is to figure out the number of zeros you would expect to see if the fitted model were truly the model that created your data.

# Simulate negative binomial data

To demonstrate this, I'll make a dataset based on a negative binomial model with a single explanatory variable.  

Since this is a generalized linear model, I first calculate the means based on the linear predictor (the exponetiation is due to the log link).

```{r}
set.seed(16)
x = runif(200, 5, 10) # simulate explanatory variable
b0 = 1 # set value of intercept
b1 = 0.25 # set value of intercept
means = exp(b0 + b1*x) # true means
```

Then I can use the means along with my chosen value of `theta` to simulate data from the negative binomial distribution.

```{r}
theta = 0.25
y = rnbinom(200, mu = means, size = theta)
```

Now that I've made some data I can fit a model.  Since I'm using a negative binomial GLM with `x` as the explanatory variable, which is how I created the data, this model should work well.  The `glm.nb()` function is in package **MASS**.

```{r}
fit1 = glm.nb(y ~ x)
```

I'm going to go directly to checking for excess zeros, but I would usually look at residual plots and check for overdispersion to check model fit.

# [Checking for excess zeros](#checking-for-excess-zeros)

The observed data has 76 0 values in it (out of 200).

```{r}
sum(y == 0)
```

How many zeros is expected given the model?  I need the model estimated means and theta to anwer this.  I can get the means via `predict()` and I can pull `theta` out of the model `summary()`.

```{r}
preds = predict(fit1, type = "response") # estimated means
esttheta = summary(fit1)$theta # estimated theta
```

For discrete distributions like the negative binomial, the *density* distribution functions (which start with "d") return the probability that the observation is equal to the given value.  This means I can use `dnbinom()` to calculate the probability of an observation being 0 for every row in the dataset if I provide values for the parameters of the distribution of each observation.  

Based on the model, the distribution of each observation is negative binomial with a model estimated mean and the overall theta.

```{r}
prop0 = dnbinom(x = 0, mu = preds, size = esttheta )
```

The sum these probabilities is an estimate of the number of zero values expected by the model (see [here](https://data.library.virginia.edu/getting-started-with-hurdle-models/) for another example).  I'll round this to the nearest integer.

```{r}
round( sum(prop0) )
```

The expected number of 0 values is ~72, very close to the 76 observed in the data.  This is no big surprise, since I fit the same model that I used to create the data.

# [An example with excess zeros](#an-example-with-excess-zeros)

The example above demonstrates a model that fits the data.  Let me finish by fitting a model to data that has more zeros than expected by the distribution.  This can be done by fitting a Poisson GLM instead of a negative binomial GLM to the data above.

```{r}
fit2 = glm(y ~ x, family = poisson)
```

Remember the data contain 76 zeros.

```{r}
sum(y == 0)
```

But, based on the Poisson model, we expect no 0 values.  These data are zero-inflated compared to the Poisson distribution, and we'd need a different option for fitting these data.

```{r}
round( sum( dpois(x = 0,
           lambda = predict(fit2, type = "response") ) ) )
```
