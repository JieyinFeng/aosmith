---
title: 'Analysis essentials: An example directory structure for an analysis using R'
author: Ariel Muldoon
date: '2018-10-26'
slug: an-example-directory-structure
categories:
  - statistics
  - r
tags:
  - analysis
draft: TRUE
description: "I go through an example of the directory structure I used to organize my data, analysis scripts, and outputs for a recent collaborative analysis I did using R."
---

When I was in my last quarter of my statistics MS I remember going to one of my professors and saying something along the lines of *"I definitely know a lot about certain statistical approaches, but if someone hands me a dataset I'm not sure I know where to start."*  I was missing the practical skills involved in doing an analysis, which is so much more than statistical methodology.

There are a lot of practical skills involved in doing an analysis that are essential but that I rarely (never?) see included in the curriculum, statistics or otherwise.  These are skills like how to organize your data, approaches for QAQC, and setting up a naming algorithm for files.  We all need to to these things, but too often we end up on our own figuring things out.

There have been some nice papers that have come out recently that I keep in my back pocket to give to students when they need them, such as [Good enough practices in scientific computing](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510) by Wilson et al. and [Data organization in spreadsheets](https://peerj.com/preprints/3183/) by Broman and Woo.  We need more papers on these kinds of topics!  

In this post I go over something something that took me a long time to 1., realize was pretty darn important and 2., actually use, which is organizing a directory of my data, scripts, and output when doing any analysis.  I refer to this as setting up my *directory structure*.

Some of this can be generalized to any set of analysis tools, but the tools I use are specifically related to using R for the analysis.  

# [The root directory](#the-root-directory)

The first thing I do is create a folder that is going to hold all the files for the analysis.  This folder is called the *root directory* because it is going to be at the top level of the hierarchy of folders used for analysis.  Since this was a discrete set of analyses that I was going to do one time, this relatively simple set-up worked well for me.

I use [RStudio Projects](https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects) for my analyses, and I create a project file (ending in `.Rproj`) in my root directory.  RStudio Projects are mostly for convenience, since they make it easy to go back to my analysis where I left off, but doing this also helps me use relative file paths in my work.

If I switch to a different computer while working the analysis project (like when I work at home), I move the root directory and not only individual files.

# [Relative file paths](#relative-file-paths)

Not so many years ago, I was laboriously writing out my file path for setting the working directory in `setwd()` or otherwise hard-coding file paths.  And then I'd work at home one day and have to manually update all those file paths.  

All my scripts had code like

```{r, eval = FALSE}
# Directory when at work, uncomment as needed
setwd("N:/Atwork/filepath/tomyfiles")
# Directory when at home, uncomment as needed
# setwd("C:/Users/Owner/Documents/Athome/forsomereason/thisfilepath/isreallylong")
```

When you can't even collaborate with yourself efficiently you know there has to be a better way.  

Enter the **here** package.  This package contains the `here()` function, which finds the root directory based on some simple heuristics.  One of these involves finding the folder in the hierarchy that contains the `.Rproj` file.  Storing my `.Rproj` file in my root directory allows me to write all file paths relative to that directory.  

Nowadays I don't set a working directory at all, but instead read and write files using the `here()` function.

For example, I can read data in from a folder called "Data" within my root directory.  This code works on any computer I move the directory to, no matter that the absolute file path has changed.

```{r, eval = FALSE}
dat = read.csv(here::here("Data", "mydata.csv"))
```

Similarly I can write code to save a final plot in a folder called "Plots".

```{r, eval = FALSE}
ggsave(file = "myplot1.png", path = here::here("Plots"))
```

Package **here** is great for simple directory structures like mine.  For more complicated ones you may need the advanced options available in package **rprojroot**.

(If you're not convinced relative file paths are useful, see [Jenny Bryan's blog post](https://www.tidyverse.org/articles/2017/12/workflow-vs-script/) about project-oriented workflows.)

# Data folder

One of the my standard sub-folders within my root directory is the "Data" folder.  I store the data for analysis in this folder.  I keep both original datasets from the domain expert and any cleaned versions that I create here.  I read datasets into R for exploration and analysis as I demonstrated above via the **here** package.

# Exploration folder

I always spend a considerable amount of time doing what a mentor of mine called "becoming one with the dataset" `r emo::ji("person_in_lotus_position")`.  This work includes making many different data summaries and as well as making a *lot* of exploratory graphics.  I store the files for this work in the "Exploration" folder.

These days I do my R coding work for projects like this exclusively within R markdown (`.Rmd`) files instead of R scripts.  The exploration files, in particular, I write so that I can easily share them with not only my future self but also my domain-expert collaborators.  This means I have to be extremely strict with myself about going back and writing lucid comments detailing my understanding of the project as a whole, of individual variables, and things I notice as I explore the data.  I will talk more about my approach to using R markdown files for exploration and analysis in a future "Analysis essentials" post so (even though I'm tempted) I won't go into any more detail here.

For this particular project I was doing separate analyses for data collected at different sites.  Given the domain expert considered each site separately, I used distinct files to explore the data at each of the four sites.  

I adopted a naming algorithm involving dates and site names following some of the suggestions in Jenny Bryan's ["naming things" slides](https://speakerdeck.com/jennybc/how-to-name-files).  For example, my R markdown file names looked like `2017-06_watershed_revisited_explore_site1_do.Rmd`, and I had HTML output files with the same names that I could send to my collaborator for review.  

# Analysis folder

The "Analysis" sub-folder is where I stored the R code files for the statistical analyses.  I again used R markdown files, this time with comments and discussion primarily written for my future self (these end up looking suspiciously like comments I make for collaborators other than my future self `r emo::ji("stuck_out_tongue_winking_eye")`).  Having the HTML output files means I can easily go back and see what I did and why along with the output without having to re-run my code.

I also put specific scripts for making publication-ready graphics of the raw data for the manuscript in this folder.  Code for plots of statistical results was contained in the analysis files.  

In this particular project I had some analyses that ended up being extremely time-consuming to run.  I saved those model objects into the "Analysis" folder as `.Rdata` files so I wouldn't have to re-run the models later to extract output, etc.  Looking back now it might have been nice to save this in a sub-folder within "Analysis".

I wrote up a final description of the statistical methods for my collaborator, which I also saved in this folder.  

# Plots folder

I store all "publication-ready" plots in this folder.  I've found it's easier to have plots stored separately, otherwise the "Analysis" folder gets so busy things are hard to find.

# Results folder

I didn't use the "Results" folder much for this project because I wasn't asked to make any tables of statistical results.  I did save final estimates as CSV files here so we would have these in an easy-to-use format if needed.

In past projects I used this folder (possibly with a different name, like "Tables") as a place to save publication-ready tables I made using R.

# Miscellaneous files

Some files don't fit within the 5 sub-folders I describe above, and those files ended up floating around in my root directory.  These files range from publications I tracked down to figure out the analysis approach of a previous study in the same location to drafts of the manuscript that I reviewed.  I see now I probably should have had at least one additional sub-folder to help with the organization of these sorts of files.

I finished this project a year ago and had to revisit things this week to pull out some example code for a consulting client.  I was definitely able to quickly find the code I was looking for; that's a pretty successful directory structure in my book. 
